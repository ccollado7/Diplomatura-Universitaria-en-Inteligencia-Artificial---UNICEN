{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase 4-Machine Translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPu_fXBljrJj"
      },
      "source": [
        "#  Machine translation\n",
        "\n",
        "La tarea aquí presentada consiste en traducir de un idioma a otro utilizando técnicas de deep learning. En partícular, la tarea es traducir del frances al ingles utilizando una red LSTM sequence to sequences. \n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "`elle est non seulement belle mais aussi intelligente. => she is not only beautiful but also intelligent.`\n",
        "\n",
        "El tutorial está basado en [Pytorch From Scratch: Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), pero en vez de attention se utilizará LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkSXTb5z9Mnt"
      },
      "source": [
        "# Imports\n",
        "import io\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYA8owSm9yr0"
      },
      "source": [
        "# Download the data\n",
        "import requests, zipfile\n",
        "\n",
        "zip_file_url = 'https://download.pytorch.org/tutorial/data.zip'\n",
        "r = requests.get(zip_file_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI8xOEJS9yzW",
        "outputId": "9694b028-e613-46b1-ae61-6a0201ab1216"
      },
      "source": [
        "\n",
        "N = 10  # print the 10 first lines\n",
        "with open('data/eng-fra.txt') as f:\n",
        "  for i in range(N):\n",
        "    line = next(f).strip()\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tVa !\n",
            "Run!\tCours !\n",
            "Run!\tCourez !\n",
            "Wow!\tÇa alors !\n",
            "Fire!\tAu feu !\n",
            "Help!\tÀ l'aide !\n",
            "Jump.\tSaute.\n",
            "Stop!\tÇa suffit !\n",
            "Stop!\tStop !\n",
            "Stop!\tArrête-toi !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At3tp3Q89y6i"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "    self.n_words = 3  # Count SOS and EOS and PAD\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1\n",
        "\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s\n",
        "\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading lines...\")\n",
        "\n",
        "  # Read the file and split into lines\n",
        "  lines = io.open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "      read().strip().split('\\n')\n",
        "\n",
        "  # Split every line into pairs and normalize\n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "  # Reverse pairs, make Lang instances\n",
        "  if reverse:\n",
        "      pairs = [list(reversed(p)) for p in pairs]\n",
        "      input_lang = Lang(lang2)\n",
        "      output_lang = Lang(lang1)\n",
        "  else:\n",
        "      input_lang = Lang(lang1)\n",
        "      output_lang = Lang(lang2)\n",
        "\n",
        "  return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRw9bg72-CIe"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "      len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "      p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rpF1wJhnQaU"
      },
      "source": [
        "Vamos a explorar un poco de los lenguajes. Ver la cantidad de palabras y su distribución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkoPYoJY-Eqz",
        "outputId": "9d7efafe-ae80-46da-da21-ae3425e5cda5"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted words:\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4346\n",
            "eng 2804\n",
            "['c est un mordu de cinema .', 'he s a movie buff .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtaBQRpm-LK1"
      },
      "source": [
        "def plot_lang(lang, top_k=100):\n",
        "  words = list(lang.word2count.keys())\n",
        "  words.sort(key=lambda w: lang.word2count[w], reverse=True)\n",
        "  print(words[:top_k])\n",
        "  count_occurences = sum(lang.word2count.values())\n",
        "\n",
        "  accumulated = 0\n",
        "  counter = 0\n",
        "\n",
        "  while accumulated < count_occurences * 0.8:\n",
        "    accumulated += lang.word2count[words[counter]]\n",
        "    counter += 1\n",
        "\n",
        "  print(f\"The {counter * 100 / len(words)}% most common words \"\n",
        "        f\"account for the {accumulated * 100 / count_occurences}% of the occurrences\")\n",
        "  plt.bar(range(100), [lang.word2count[w] for w in words[:top_k]])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "sDF1hyWq-LOI",
        "outputId": "c797492e-7c8a-4e7e-a8e8-71ea8cd4c4b7"
      },
      "source": [
        "plot_lang(input_lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.', 'je', 'suis', 'est', 'vous', 'pas', 'de', 'il', 'nous', 'tu', 'etes', 'ne', 'es', 'en', 'a', 'n', 'un', 'sommes', 'elle', 'la', 'tres', 'c', 'que', 'le', 'sont', 'j', 'une', 'd', 'ai', 'pour', 'l', 'ils', 'plus', 'ce', 'des', 'me', 'vais', 'elles', 'moi', '!', 'mon', 'trop', 'train', 'fort', 'si', 'ici', 'du', 'toujours', 'toi', 'tout', 'tous', 'les', '?', 'vraiment', 'sur', 't', 'te', 'm', 'dans', 'avec', 'avoir', 'encore', 'qu', 'tom', 'votre', 'au', 'peur', 'y', 'desole', 'bien', 'ca', 'bon', 'fais', 'toutes', 'heureux', 'faire', 'etre', 'son', 'aussi', 'assez', 'lui', 'tellement', 'ma', 'mes', 'fatigue', 'par', 'et', 'fait', 'ton', 'se', 'juste', 'maintenant', 'grand', 'desolee', 'avons', 'allons', 'peu', 'deux', 'on', 'vieux']\n",
            "The 4.674188349067465% most common words account for the 80.0371543427945% of the occurrences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Erqr0ngc-LRQ",
        "outputId": "ec7a4bc8-6d2a-4bb8-cfb5-19956d884738"
      },
      "source": [
        "plot_lang(output_lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.', 'i', 're', 'you', 'm', 'he', 'not', 'is', 'a', 'to', 'we', 's', 'the', 'very', 'are', 'of', 'she', 'am', 'they', 'in', 'going', 'my', 'for', 'all', 'at', 'here', 'with', 'that', 'good', 'as', 'your', 't', 'me', 'too', 'this', 'sorry', 'on', 'glad', 'it', 'than', 'now', 'happy', 'about', '?', 'aren', 'so', 'tired', 'afraid', 'sure', 'right', 'an', 'his', 'out', 'really', 'one', 'busy', 'still', 'just', 'old', 'always', 'tom', 'looking', 'be', 'friend', 'no', 'her', 'ready', 'by', '!', 'and', 'teacher', 'from', 'getting', 'him', 'alone', 'being', 'home', 'up', 'have', 'go', 'doing', 'help', 'see', 'proud', 'man', 'married', 'kind', 'who', 'waiting', 'yet', 'young', 'person', 'done', 'late', 'friends', 'new', 'anymore', 'hungry', 'such', 'sick']\n",
            "The 4.85540878257765% most common words account for the 80.00500226665207% of the occurrences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH1zDAgynohU"
      },
      "source": [
        "## Para entrenar\n",
        "\n",
        "El modelo consistirá en un encoder que con\n",
        "\n",
        "Vamos a mapear las entradas/saludas de nuestro modelo a un vector de IDs.\n",
        "\n",
        "```\n",
        "Representation of an input sentece:\n",
        "[2, 2, 2, 2, 2, 2, 0, 3, 4, 5, 6, 1]\n",
        "PAD PAD PAD PAD PAD PAD SOS j ai ans . EOS\n",
        "\n",
        "Representation of an partial sentece:\n",
        "[0, 3, 4, 5, 1, 2, 2, 2, 2, 2, 2, 2]\n",
        "SOS i m . EOS PAD PAD PAD PAD PAD PAD PAD\n",
        "\n",
        "Representation of an target sentece:\n",
        "[3, 4, 5, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
        "i m . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
        "```\n",
        "\n",
        "Es importante n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSApO-_z-LUr"
      },
      "source": [
        "def to_train(input_lang, output_lang, pairs, max_len=MAX_LENGTH+2):\n",
        "  x_input = []\n",
        "  x_output = []\n",
        "  target = []\n",
        "  for i, o in pairs:\n",
        "    s_i = [2] * max_len + [0] + [input_lang.word2index[w] for w in i.split(\" \")] + [1]\n",
        "    s_o = [0] + [output_lang.word2index[w] for w in o.split(\" \")] + [1] + [2] * max_len\n",
        "    s_to = s_o[1:] + [2]\n",
        "    x_input.append(s_i[-max_len:])\n",
        "    x_output.append(s_o[:max_len])\n",
        "    target.append(s_to[:max_len])\n",
        "  return x_input, x_output, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28dxM1QC-LYA"
      },
      "source": [
        "x_input, x_partial, y = to_train(input_lang, output_lang, pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1CTz1nl-Zwe",
        "outputId": "341ee632-5f15-4723-d141-e83918c74d4e"
      },
      "source": [
        "print('Representation of an input sentece:')\n",
        "print(x_input[0])\n",
        "print(' '.join([input_lang.index2word[w] for w in x_input[0]]))\n",
        "print('\\nRepresentation of an partial sentece:')\n",
        "print(x_partial[0])\n",
        "print(' '.join([output_lang.index2word[w] for w in x_partial[0]]))\n",
        "print('\\nRepresentation of an target sentece:')\n",
        "print(y[0])\n",
        "print(' '.join([output_lang.index2word[w] for w in y[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Representation of an input sentece:\n",
            "[2, 2, 2, 2, 2, 2, 0, 3, 4, 5, 6, 1]\n",
            "PAD PAD PAD PAD PAD PAD SOS j ai ans . EOS\n",
            "\n",
            "Representation of an partial sentece:\n",
            "[0, 3, 4, 5, 1, 2, 2, 2, 2, 2, 2, 2]\n",
            "SOS i m . EOS PAD PAD PAD PAD PAD PAD PAD\n",
            "\n",
            "Representation of an target sentece:\n",
            "[3, 4, 5, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "i m . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVKOY6mCr6R"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "def masked_categorical_crossentropy(y_true, y_pred):\n",
        "    y_true = K.cast(K.flatten(y_true), np.int32)\n",
        "    y_pred = K.reshape(y_pred, [-1, y_pred.shape[-1]])\n",
        "    loss = sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    mask = tf.where(y_true==2, 0.0, 1.0)\n",
        "    return loss * mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QelkGg2-dzS",
        "outputId": "5dcd7599-d23a-43b0-b2d8-d2fbf4ef3cec"
      },
      "source": [
        "hidden = 300\n",
        "\n",
        "ie = Input((MAX_LENGTH+2,), name='origen')\n",
        "e = Embedding(input_lang.n_words, hidden, name='embedding-org')(ie)\n",
        "_, hs, hc = LSTM(hidden, name='encoder', return_state=True)(e)\n",
        "\n",
        "id = Input((MAX_LENGTH+2,), name='dest')\n",
        "e = Embedding(output_lang.n_words, hidden, name='embedding-dest')(id)\n",
        "d = LSTM(hidden, name='decoder', return_sequences=True)(e, initial_state=[hs, hc])\n",
        "d = Dense(output_lang.n_words, activation='softmax')(d)\n",
        "\n",
        "model = Model(inputs=[ie, id], outputs=d)\n",
        "model.compile(loss=masked_categorical_crossentropy, optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "origen (InputLayer)             [(None, 12)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dest (InputLayer)               [(None, 12)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding-org (Embedding)       (None, 12, 300)      1303800     origen[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding-dest (Embedding)      (None, 12, 300)      841200      dest[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "encoder (LSTM)                  [(None, 300), (None, 721200      embedding-org[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder (LSTM)                  (None, 12, 300)      721200      embedding-dest[0][0]             \n",
            "                                                                 encoder[0][1]                    \n",
            "                                                                 encoder[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 12, 2804)     844004      decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,431,404\n",
            "Trainable params: 4,431,404\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kzx-OTLFIqU",
        "outputId": "dbff9bfe-46be-4c0c-cfb5-8d91b3313533"
      },
      "source": [
        "model.fit([np.asarray(x_input), np.asarray(x_partial)], np.asarray(y), epochs=50, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 12s 34ms/step - loss: 2.6242\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.8283\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 1.6250\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.5089\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.3941\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.2881\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.2028\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 1.1281\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 1.0623\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 0.9991\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.9380\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.8786\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.8244\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.7710\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 0.7193\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.6707\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.6241\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.5795\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.5365\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.4973\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.4587\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 0.4230\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.3877\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.3560\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.3273\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.2994\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.2742\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.2514\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.2301\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.2097\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1921\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.1755\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1596\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1464\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1340\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 0.1220\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1122\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.1034\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0955\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0874\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0804\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0739\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.0690\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.0644\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0603\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0555\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0520\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0492\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0466\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.0432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8da1c59ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwh1IEykFQx5"
      },
      "source": [
        "def gen_translation(model, text, input_lang, output_lang, max_len=MAX_LENGTH+2):\n",
        "\n",
        "  text =  [2] * max_len + [0] + [input_lang.word2index[w] for w in text.split(\" \")] + [1]\n",
        "  text = np.asarray([text[-max_len:]])\n",
        "  out = [0] + [2] * max_len\n",
        "  out = [out[:max_len]]\n",
        "  for i in range(1, max_len):\n",
        "    np_out = np.asarray(out)\n",
        "    p = model.predict([text, np_out])\n",
        "    out[0][i] = np.argmax(p, axis=-1)[0, i-1]\n",
        "    if np.argmax(p, axis=-1)[0, i-1] == 1:\n",
        "      break\n",
        "\n",
        "  return ' '.join([output_lang.index2word[idx] for idx in out[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J_QvjeQPJ_4n",
        "outputId": "f5759f31-623b-42f8-90f3-080172f0cc47"
      },
      "source": [
        "gen_translation(model, pairs[40][0], input_lang, output_lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SOS i m safe . EOS PAD PAD PAD PAD PAD PAD'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3r4UrDGKFBq",
        "outputId": "beae51a1-4a3b-45a1-fb77-6672ddf57781"
      },
      "source": [
        "\n",
        "for i in range(40):\n",
        "  print('> {}'.format(pairs[i][0]))\n",
        "  print('= {}'.format(pairs[i][1]))\n",
        "  print('< {}'.format(gen_translation(model,\n",
        "                                      pairs[i][0],\n",
        "                                      input_lang,\n",
        "                                      output_lang)))\n",
        "  print('*' * 40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> j ai ans .\n",
            "= i m .\n",
            "< SOS i m years old . EOS PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je vais bien .\n",
            "= i m ok .\n",
            "< SOS i m all right . EOS PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> ca va .\n",
            "= i m ok .\n",
            "< SOS i m fine . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis gras .\n",
            "= i m fat .\n",
            "< SOS i m fat . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis gros .\n",
            "= i m fat .\n",
            "< SOS i m fat . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis en forme .\n",
            "= i m fit .\n",
            "< SOS i m fit . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis touche !\n",
            "= i m hit !\n",
            "< SOS i m hit ! EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis touchee !\n",
            "= i m hit !\n",
            "< SOS i m hit ! EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis malade .\n",
            "= i m ill .\n",
            "< SOS i m sick . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis triste .\n",
            "= i m sad .\n",
            "< SOS i m sad . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis timide .\n",
            "= i m shy .\n",
            "< SOS i m shy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis mouille .\n",
            "= i m wet .\n",
            "< SOS i m wet . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis mouillee .\n",
            "= i m wet .\n",
            "< SOS i m wet . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> il est mouille .\n",
            "= he s wet .\n",
            "< SOS he s wet . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis gras .\n",
            "= i am fat .\n",
            "< SOS i m fat . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis revenu .\n",
            "= i m back .\n",
            "< SOS i m back . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> me revoila .\n",
            "= i m back .\n",
            "< SOS i m back . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis chauve .\n",
            "= i m bald .\n",
            "< SOS i m bald . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis occupe .\n",
            "= i m busy .\n",
            "< SOS i m busy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis occupee .\n",
            "= i m busy .\n",
            "< SOS i m busy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis calme .\n",
            "= i m calm .\n",
            "< SOS i m calm . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> j ai froid .\n",
            "= i m cold .\n",
            "< SOS i am cold . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> j en ai fini .\n",
            "= i m done .\n",
            "< SOS i m done . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> tout va bien .\n",
            "= i m fine .\n",
            "< SOS i m fine . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je vais bien .\n",
            "= i m fine .\n",
            "< SOS i m all right . EOS PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> ca va .\n",
            "= i m fine .\n",
            "< SOS i m fine . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis libre !\n",
            "= i m free !\n",
            "< SOS i m free ! EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis libre .\n",
            "= i m free .\n",
            "< SOS i m free . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis disponible .\n",
            "= i m free .\n",
            "< SOS i m available . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis repu !\n",
            "= i m full .\n",
            "< SOS i m full . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis rassasie !\n",
            "= i m full .\n",
            "< SOS i m full . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis content .\n",
            "= i m glad .\n",
            "< SOS i m glad . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis chez moi .\n",
            "= i m home .\n",
            "< SOS i m home . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis en retard .\n",
            "= i m late .\n",
            "< SOS i m late . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis paresseux .\n",
            "= i m lazy .\n",
            "< SOS i m lazy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis faineant .\n",
            "= i m lazy .\n",
            "< SOS i m lazy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis paresseuse .\n",
            "= i m lazy .\n",
            "< SOS i am lazy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je suis faineante .\n",
            "= i m lazy .\n",
            "< SOS i m lazy . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je vais bien .\n",
            "= i m okay .\n",
            "< SOS i m all right . EOS PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> je me porte bien .\n",
            "= i m okay .\n",
            "< SOS i m okay . EOS PAD PAD PAD PAD PAD PAD\n",
            "****************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbdwmI3_KLOm",
        "outputId": "42e54dc7-8cc4-4d08-be1c-6363334afdd1"
      },
      "source": [
        "for i in range(40):\n",
        "  print('> {}'.format(pairs[-i][0]))\n",
        "  print('= {}'.format(pairs[-i][1]))\n",
        "  print('< {}'.format(gen_translation(model,\n",
        "                                      pairs[-i][0],\n",
        "                                      input_lang,\n",
        "                                      output_lang)))\n",
        "  print('*' * 40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> j ai ans .\n",
            "= i m .\n",
            "< SOS i m years old . EOS PAD PAD PAD PAD PAD\n",
            "****************************************\n",
            "> il est un des candidats aux presidentielles americaines .\n",
            "= he is one of the american presidential candidates .\n",
            "< SOS he is one of the american presidential candidates . EOS PAD\n",
            "****************************************\n",
            "> ils collectent des dons pour l eglise .\n",
            "= they are collecting contributions for the church .\n",
            "< SOS they are collecting contributions for the church . EOS PAD PAD\n",
            "****************************************\n",
            "> j ai quelques difficultes a compiler ce programme .\n",
            "= i m having some problems compiling this software .\n",
            "< SOS i m having some problems compiling this software . EOS PAD\n",
            "****************************************\n",
            "> il entreprend des experiences dans son laboratoire .\n",
            "= he is carrying out experiments in his laboratory .\n",
            "< SOS he is carrying out experiments in his laboratory . EOS PAD\n",
            "****************************************\n",
            "> elle est non seulement belle mais aussi intelligente .\n",
            "= she is not only beautiful but also intelligent .\n",
            "< SOS she is not only beautiful but also intelligent . EOS PAD\n",
            "****************************************\n",
            "> nous enquetons sur le meurtre de tom jackson .\n",
            "= we re investigating the murder of tom jackson .\n",
            "< SOS we re investigating the murder of tom jackson . EOS PAD\n",
            "****************************************\n",
            "> elle est tres receptive a la suggestion hypnotique .\n",
            "= she s very susceptible to hypnotic suggestion .\n",
            "< SOS she s very susceptible to hypnotic suggestion . EOS PAD PAD\n",
            "****************************************\n",
            "> elle trouve toujours a redire aux autres .\n",
            "= she is always finding fault with other people .\n",
            "< SOS she is always finding fault with other people . EOS PAD\n",
            "****************************************\n",
            "> je pense apprendre le coreen le semestre prochain .\n",
            "= i m thinking of learning korean next semester .\n",
            "< SOS i m thinking of learning korean next semester . EOS PAD\n",
            "****************************************\n",
            "> tu es probablement trop jeune pour le comprendre .\n",
            "= you re probably too young to understand this .\n",
            "< SOS you re probably too young to understand this . EOS PAD\n",
            "****************************************\n",
            "> vous etes probablement trop jeune pour le comprendre .\n",
            "= you re probably too young to understand this .\n",
            "< SOS you re probably too young to understand this . EOS PAD\n",
            "****************************************\n",
            "> tu es trop critique des defauts des autres .\n",
            "= you are too critical of others shortcomings .\n",
            "< SOS you are too critical of others shortcomings . EOS PAD PAD\n",
            "****************************************\n",
            "> vous etes trop critique des defauts des autres .\n",
            "= you are too critical of others shortcomings .\n",
            "< SOS you are too critical of others shortcomings . EOS PAD PAD\n",
            "****************************************\n",
            "> nous attendons la publication de son ouvrage .\n",
            "= we are expecting the publication of his book .\n",
            "< SOS we are expecting the publication of his book . EOS PAD\n",
            "****************************************\n",
            "> elle est forte pour inventer des histoires interessantes .\n",
            "= she is good at making up interesting stories .\n",
            "< SOS she is good at making up interesting stories . EOS PAD\n",
            "****************************************\n",
            "> elle trouve toujours des defauts a son mari .\n",
            "= she is always finding fault with her husband .\n",
            "< SOS she is always finding fault with her husband . EOS PAD\n",
            "****************************************\n",
            "> je lui dis constamment de bien se comporter .\n",
            "= i m constantly telling her to behave herself .\n",
            "< SOS i m constantly telling her to behave herself . EOS PAD\n",
            "****************************************\n",
            "> c est un interprete dans une banque internationale .\n",
            "= he s an interpreter in an international bank .\n",
            "< SOS he s an interpreter in an international bank . EOS PAD\n",
            "****************************************\n",
            "> il est expert en litterature francaise .\n",
            "= he is well acquainted with french literature .\n",
            "< SOS he is well acquainted with french literature . EOS PAD PAD\n",
            "****************************************\n",
            "> il bataille encore avec les croyances religieuses .\n",
            "= he is still grappling with religious beliefs .\n",
            "< SOS he is still grappling with religious beliefs . EOS PAD PAD\n",
            "****************************************\n",
            "> il est competent en espagnol et en italien .\n",
            "= he is proficient in both spanish and italian .\n",
            "< SOS he is proficient in both spanish and italian . EOS PAD\n",
            "****************************************\n",
            "> il quitte narita pour hawaii ce soir .\n",
            "= he is leaving narita for hawaii this evening .\n",
            "< SOS he is leaving narita for hawaii this evening . EOS PAD\n",
            "****************************************\n",
            "> il s amuse en jouant aux jeux videos .\n",
            "= he is amusing himself by playing video games .\n",
            "< SOS he is amusing himself by playing video games . EOS PAD\n",
            "****************************************\n",
            "> il trouve toujours a redire aux autres .\n",
            "= he is always finding fault with other people .\n",
            "< SOS he is always finding fault with other people . EOS PAD\n",
            "****************************************\n",
            "> nous discuterons du probleme demain .\n",
            "= we re going to discuss the problem tomorrow .\n",
            "< SOS we re going to discuss the problem tomorrow . EOS PAD\n",
            "****************************************\n",
            "> nous avons des problemes avec notre nouveau voisin .\n",
            "= we are having trouble with our new neighbor .\n",
            "< SOS we are having trouble with our new neighbor . EOS PAD\n",
            "****************************************\n",
            "> il me tarde de recevoir votre reponse .\n",
            "= i m looking forward to receiving your reply .\n",
            "< SOS i m looking forward to receiving your reply . EOS PAD\n",
            "****************************************\n",
            "> j ai hate de recevoir ta reponse .\n",
            "= i m looking forward to receiving your reply .\n",
            "< SOS i m looking forward to receiving your reply . EOS PAD\n",
            "****************************************\n",
            "> je pense cloturer mon compte d epargne .\n",
            "= i am thinking of closing my savings account .\n",
            "< SOS i am thinking of closing my savings account . EOS PAD\n",
            "****************************************\n",
            "> je suis etonne par ton attitude irresponsable .\n",
            "= i am alarmed by your irresponsible attitude .\n",
            "< SOS i am alarmed by your irresponsible attitude . EOS PAD PAD\n",
            "****************************************\n",
            "> je suis inquiet de votre attitude irresponsable .\n",
            "= i am alarmed by your irresponsible attitude .\n",
            "< SOS i am alarmed by your irresponsible attitude . EOS PAD PAD\n",
            "****************************************\n",
            "> il est une autorite reconnue sur le sujet .\n",
            "= he is a recognized authority on the subject .\n",
            "< SOS he is a recognized authority on the subject . EOS PAD\n",
            "****************************************\n",
            "> nous avons des invites ce soir .\n",
            "= we re having some guests over this evening .\n",
            "< SOS we re having some guests over this evening . EOS PAD\n",
            "****************************************\n",
            "> nous nous rejouissons de vous revoir .\n",
            "= we are looking forward to seeing you again .\n",
            "< SOS we are looking forward to seeing you again . EOS PAD\n",
            "****************************************\n",
            "> elles sont disposees a discuter du probleme .\n",
            "= they are willing to talk about the problem .\n",
            "< SOS they are willing to talk about the problem . EOS PAD\n",
            "****************************************\n",
            "> ils sont disposes a discuter du probleme .\n",
            "= they are willing to talk about the problem .\n",
            "< SOS they are willing to talk about the problem . EOS PAD\n",
            "****************************************\n",
            "> ils parlent de ce qu ils vont chanter .\n",
            "= they are talking about what they will sing .\n",
            "< SOS they are talking about what they will sing . EOS PAD\n",
            "****************************************\n",
            "> je suis le porte parole de cette institution .\n",
            "= i m the spokesperson for this organization .\n",
            "< SOS i m the spokesperson for this organization . EOS PAD PAD\n",
            "****************************************\n",
            "> je suis le porte parole de cette organisation .\n",
            "= i m the spokesperson for this organization .\n",
            "< SOS i m the spokesperson for this organization . EOS PAD PAD\n",
            "****************************************\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}