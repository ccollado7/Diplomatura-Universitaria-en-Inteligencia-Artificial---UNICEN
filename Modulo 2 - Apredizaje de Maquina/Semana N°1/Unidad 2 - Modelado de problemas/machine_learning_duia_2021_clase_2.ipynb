{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-learning-duia-2021-clase-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsyZMUTu4QeQ"
      },
      "source": [
        "# Aprendizaje de Máquinas (Machine Learning)\n",
        "## Clase 2: Modelado de problemas de Machine Learning\n",
        "\n",
        "### 1. Configuración del ambiente\n",
        "\n",
        "Antes que empezar a trabajar, vamos a preparar el ambiente.\n",
        "Para ello:\n",
        "* Instalamos todos los paquetes que vamos a necesitar para trabajar. Lo hacemos utilizando el controlador de paquetes de Python ```pip```. Cada vez que usemos ```!```en la consola, le estamos diciendo al notebook que ejecute la instrucción en la consola del sistema, no en la de Python.\n",
        "* Montamos Google Drive para guardar allí los archivos que descarguemos. En la consola nos va a aparecer una solicitud para hacer clic en una URL, loggearnos con nuestra cuenta de Google y colocar un código de autorización en una casilla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyJZLOLw4hcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21333051-ff04-4d68-c556-4b27733d8c5d"
      },
      "source": [
        "# instalamos el paquete para descargar archivos\n",
        "!pip install wget\n",
        "\n",
        "# montar la unidad de google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "from os import makedirs\n",
        "datasets_folder = '/content/gdrive/My Drive/Colab Notebooks/DUIA/2021/Machine Learning/'\n",
        "makedirs(datasets_folder, exist_ok=True)\n",
        "\n",
        "# importo numpy\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress=True) # y hago un truco para imprimir solamente 3 decimales\n",
        "\n",
        "# importo una librería para utilizar valores aleatorios\n",
        "import random\n",
        "random.seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=a07eeef4f6dba5811682e5ef6af1201c80fe955db52d7f6b1b553571518f18a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnfWXeP45u57"
      },
      "source": [
        "### 2. Acceso a datos de la clase pasada\n",
        "\n",
        "Vamos a trabajar con la partición en datos de entrenamiento, validación y test que preparamos en la clase anterior. Si el archivo no está disponible en Google Drive, volvé al Colab de la Clase 1 y ejecutá todos los bloques de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UCtVJe65zmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d8fbd6-e006-43e6-a30f-5d43049be0a2"
      },
      "source": [
        "# establecemos la ruta al archivo (si la cambiaron la clase pasada, corregir por\n",
        "# la ruta correcta)\n",
        "dataset_filename = '/content/gdrive/My Drive/Colab Notebooks/DUIA/2021/Machine Learning/housing_dataset_partitioned.pkl'\n",
        "\n",
        "# cargamos los datos preparados\n",
        "import pickle\n",
        "with open(dataset_filename, 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "# verificamos si los datos están bien cargados\n",
        "print('Variables in dataset object: {}'.format(dataset.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variables in dataset object: dict_keys(['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test', 'feature_labels', 'mu', 'sigma'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nam-LkaOhrv"
      },
      "source": [
        "### 3. Entrenando nuestro primer modelo\n",
        "\n",
        "Vamos a tomar como primer ejemplo un problema de regresión, utilizando los datos que preparamos en la clase anterior.\n",
        "\n",
        "El problema que plantearemos es el de predecir la mediana de precio de una propiedad (en miles de dólares) en función de sus características. Se trata de un problema de regresión debido a que la variable objetivo $y$ (el precio de la propiedad) es una variable contínua.\n",
        "\n",
        "Para entrenar un modelo necesitamos datos de entrenamiento. En nuestro caso, utilizaremos el conjunto $X_\\text{train}$ y sus anotaciones $y_\\text{train}$, que preparamos la clase pasada. Recordemos que esos datos ya fueron particionados representativamente, estás estandarizados de acuerdo a su media y desvío y fueron corregidos previamente para eliminar potenciales sesgos.\n",
        "\n",
        "El modelo que utilizaremos es un modelo de regresión lineal regularizado, conocido como [Ridge regression](https://en.wikipedia.org/wiki/Tikhonov_regularization). No se preocupen por los detalles, los vamos a ver la próxima clase. Lo que sí tenemos que saber ahora es que este modelo es capaz de resolver un problema de regresión lineal, y que tiene un hiperparámetro que usualmente se llama $\\lambda$, pero que en Sklearn se denota con $\\alpha$, que controla el nivel de regularización. La regularización es una estrategia matemática que se utiliza durante el entrenamiento para evitar el overfitting. Idealmente, su utilización nos permite mejorar la capacidad de generalización del modelo. Sin embargo, a veces puede ocurrir que la utilicemos y que los resultados no mejoren.\n",
        "\n",
        "Haremos un primer entrenamiento del modelo utilizando un parámetro $\\alpha=0$ (lo que equivale a usar un modelo de regresión lineal tradicional, sin regularización). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZadPFJ2h6PI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ea9f6f-ae3b-49bb-89c9-6132fee549d8"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# creamos el objeto Ridge, que modela el método de Ridge regression\n",
        "# - alpha: el parámetro de regularización\n",
        "# - fit_intercept: por ahora no nos interesa, dejémoslo en True\n",
        "model = Ridge(alpha=0.0, fit_intercept=True)\n",
        "# lo fitteamos (entrenamos) con nuestros datos de entrenamiento\n",
        "model.fit(dataset['X_train'], dataset['y_train'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "      normalize=False, random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LINDaHJEjo5L"
      },
      "source": [
        "Listo! El modelo ya está entrenado. Internamente, la función .fit() ha encontrado la configuración óptima de parámetros para minimizar el error cuadrático medio sobre los datos de entrenamiento. En un modelo de regresión lineal, los parámetros son coeficientes que multiplican a cada feature. La suma de los valores de las features ponderadas por estos coeficientes es lo que determina la predicción final.\n",
        "\n",
        "Podemos visualizar los valores de los coeficientes aprendidos utilizando un gráfico de barras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Wdrv7Nqb7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "822a0ca7-5bf7-49c3-8cf5-138c3b4b6a69"
      },
      "source": [
        "# accedemos a los coeficientes del modelo\n",
        "theta = model.coef_\n",
        "# los imprimimos\n",
        "print('Coeficientes: {}'.format(theta))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Coefficients of the Ridge Regression model')\n",
        "plt.bar(np.arange(theta.size), np.squeeze(theta))\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Coefficient value')\n",
        "plt.xticks(np.arange(theta.size), dataset['feature_labels'], rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coeficientes: [[-1.597  1.113  0.028  0.554 -3.049  3.769 -1.429 -3.426  2.469 -1.962\n",
            "  -2.509]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S53nZViItESv"
      },
      "source": [
        "Graficar los coeficientes permite de alguna manera \"interpretar\" qué hace el modelo que aprendimos. Pero eso lo veremos en detalle en la clase de regresión. Por lo pronto, observarlos nos permite ver que efectivamente el modelo está aprendiendo algo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWX2dSyVkCs8"
      },
      "source": [
        "### 4. Validación\n",
        "\n",
        "De nada nos sirve un modelo entrenado si no chequeamos qué tan efectivo es. Más aún porque no utilizamos regularización y no chequeamos si la necesitamos o no.\n",
        "\n",
        "Lo próximo que haremos, entonces, es chequear **sobre los datos de validación** qué tan bueno es el modelo. No podemos usar los datos de test para esto, dado que, como dijimos antes, estos datos se usarán para explicar la performance del modelo final que elijamos (habiendo encontrado la configuración de $\\alpha$ óptima para nuestros datos de entrenamiento/validación).\n",
        "\n",
        "Para evaluar el modelo, primero necesitamos predecir los valores de variable objetivo, a los que llamaremos $\\hat{y}$, para cada una de las muestras de los datos de validación. Lo hacemos utilizando el método .predict() de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbiz67Kklm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35eca38-1070-423c-b495-683cf3de0e69"
      },
      "source": [
        "# usamos las features de los datos de validación para predecir la performance \n",
        "# sobre los datos de validación\n",
        "y_hat_val = model.predict(dataset['X_val'])\n",
        "# imprimimos la salida para las primeras 5 muestras\n",
        "print('y_hat: {}'.format(y_hat_val[0:5]))\n",
        "# e imprimimos la salida esperada\n",
        "print('y: {}'.format(dataset['y_val'][0:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_hat: [[33.772]\n",
            " [30.687]\n",
            " [16.142]\n",
            " [20.3  ]\n",
            " [10.138]]\n",
            "y: [[31.1]\n",
            " [31.5]\n",
            " [20. ]\n",
            " [50. ]\n",
            " [15. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asJRnDFSuBn9"
      },
      "source": [
        "Ahora necesitamos evaluar cuantitativamente qué tan buenas son estas predicciones. Para ello utilizaremos una **métrica de evaluación**. \n",
        "Para evaluar problemas de regresión existen muchas. Nosotros vamos a usar dos:\n",
        "\n",
        "El **error cuadrático medio** (mean square error, MSE) mide las diferencias entre las predicciones del modelo y los valores reales de cada muestra, penalizadas cada una al cuadrado. Se calcula como:\n",
        "$\\text{MSE} = \\frac{1}{N} \\sum_i^N {(y_i - \\hat{y}_i)}^2$, donde $N$ es el número de muestras y $y_i$ y $\\hat{y}_i$ son la predicción esperada y la producida por el modelo, respectivamente, para la muestra $i$-ésima. La ventaja de esta métrica es que penalizará más las diferencias grandes, y será más permisivo con las diferencias menos importantes.\n",
        "\n",
        "De manera similar, el **error absoluto medio** (mean absolute error, MAE) mide las diferencias absolutas entre las predicciones y los valores reales. Se calcula como: $\\text{MAE} = \\frac{1}{N} \\sum_i^N {|(y_i - \\hat{y}_i)|}_1$. Si observamos, la ecuación es similar a la anterior, sólo que reemplazamos los cuadrados por el valor absoluto (${| · |}_1$). Esta métrica asume igual importancia entre errores chicos y grandes.\n",
        "\n",
        "Hagamos la evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrgsWqS8urMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ded27f2-19c5-46a3-b48e-c9fea88959a5"
      },
      "source": [
        "def mse(y, y_hat):\n",
        "  '''\n",
        "  Función para calcular el error cuadrático medio\n",
        "  '''\n",
        "  # suma promedio de diferencias al cuadrado\n",
        "  return (1 / y.size) * np.sum((y - y_hat)**2)\n",
        "\n",
        "\n",
        "def mae(y, y_hat):\n",
        "  '''\n",
        "  Función para calcular el error absoluto medio\n",
        "  '''\n",
        "  # suma promedio de diferencias absolutas\n",
        "  return (1 / y.size) * np.sum(np.abs(y - y_hat))\n",
        "\n",
        "\n",
        "# calculamos el MSE y el MAE comparando los datos de validación\n",
        "mse_ = mse(dataset['y_val'], y_hat_val)\n",
        "mae_ = mae(dataset['y_val'], y_hat_val)\n",
        "print('MSE = {}'.format(mse_))\n",
        "print('MAE = {}'.format(mae_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE = 39.43839611558291\n",
            "MAE = 4.074660629209803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpbzuflpxNl1"
      },
      "source": [
        "¿Notamos diferencias importantes entre ambas métricas? Bueno, eso es porque cada métricas tiene sus propias unidades. Si recordamos, nuestra variable objetivo está en miles de dólares. El error cuadrático medio tiene unidades al cuadrado (miles de dólares al cuadrado)(, justamente porque estamos midiendo errores al cuadrado. Por otro lado, el error absoluto medio tiene las mismas unidades que las predicciones que estamos realizando (miles de dólares).\n",
        "\n",
        "A priori podríamos decir que el error es alto o bajo, ¿pero es el mejor modelo posible? ¡No lo sabemos! Al menos no hasta que hagamos model selection y exprimamos lo más posible el modelo que tenemos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQjGZVFJypU_"
      },
      "source": [
        "### 5. Model selection\n",
        "\n",
        "La gran mayoría de los modelos de machine learning tienen hiperparámetros. Cuando hablamos de hiperparámetros, hablamos de variables que rigen ya sea al modelo en sí o al proceso de entrenamiento del modelo, y que no se pueden aprender si no que tenemos que setearlas manualmente. \n",
        "\n",
        "Es de esperar que cambios en estos valores produzcan diferentes modelos, con lo cual es necesario que podamos escoger aquel modelo que mejor performa. A este proceso lo conocemos como **model selection**.\n",
        "\n",
        "Existen **diferentes estrategias para hacer model selection**, la mayoría basada en *estrategias greedy* que consisten en *probar diferentes configuraciones, evaluarlas y elegir la más conveniente*. La forma de hacerlo es explotando las particiones de los datos en entrenamiento y validación: elegimos una configuración, entrenamos el modelo en nuestro training set, lo evaluamos en nuestro validation set utilizando una métrica específica, elegimos una nueva configuración, y repetimos hasta agotar todas las opciones que queremos.\n",
        "\n",
        "Hay *dos estrategias* muy comunes para hacer esta búsqueda, ambas diferenciadas por la forma en la que seleccionamos una configuración: **grid search y random search**.\n",
        "\n",
        "*Grid search* es una búsqueda en la que elegimos *a priori* diferentes valores para cada hiperparámetro, y los probamos a todos. Tiene la ventaja de que te permite controlar mejor la búsqueda (dado que si encontrás un rango de valores en los que la performance es más alta, podés repetir la búsqueda en ese rango, con mayor nivel de detalle). Sin embargo, tiene un costo computacional más elevado (porque necesitamos entrenar el modelo montones de veces).\n",
        "\n",
        "*Random search* es una búsqueda alternativa en la que simplemente definimos los rangos en los que queremos explorar, y luego probamos valores aleatorios de cada hiperparámetro dentro de sus rangos predefinidos. Esta búsqueda es más eficiente (porque elegimos probar el número de combinaciones que queramos), pero más difícil de controlar.\n",
        "\n",
        "En este dibujo se entienden más o menos bien: usando grid search con muy pocos valores por hiperparámetro, puede ocurrir que se nos pierda el valor óptimo de performance. Usando random search, podemos tener la suerte de caer justo en los valores que más nos sirven.\n",
        "\n",
        "![Fuente: https://blog.usejournal.com/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85](https://miro.medium.com/max/2000/1*9W1MrRkHi0YFmBoHi9Y2Ow.png)\n",
        "\n",
        "Vamos a hacer primero una búsqueda del valor para el hiperparámetro $\\alpha$ óptimo utilizando grid search. Para ello, necesitamos escoger:\n",
        "\n",
        "1. **Los valores que queremos probar para cada hiperparámetro:** en nuestro caso, tenemos un único hiperparámetro ($\\alpha$). En general, los regularizadores se evalúan en potencias de 10 (por ejemplo: $10^k$, con $k \\in \\{-5, -4, -3, ..., 0, 1, 2, ... 5\\}$.\n",
        "2. **La métrica de evaluación:** se elige siempre pensando en la aplicación final, y en la métrica que esperamos que optimice nuestro algoritmo. Dado que el entrenamiento de este modelo de regresión en particular se realiza minimizando el error cuadrático medio, lo recomendable sería usar MSE.\n",
        "\n",
        "El siguiente código realiza diferentes pruebas, las tabula y nos muestra los resultados de la búsqueda por grid search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wik_1Rz02XRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b879d2e-57a4-4fd2-9ee6-e50aaee014b3"
      },
      "source": [
        "# definimos el rango de valores a explorar\n",
        "alpha_values_exponents = range(-5,5,1)\n",
        "\n",
        "# inicializamos el arreglo de resultados\n",
        "mse_values = np.zeros(np.asarray(alpha_values_exponents).shape)\n",
        "# y una lista de modelos\n",
        "models = []\n",
        "# probamos cada configuración\n",
        "i=0\n",
        "print('Grid search')\n",
        "print('=================')\n",
        "for k in alpha_values_exponents:\n",
        "  # calculamos alpha\n",
        "  current_alpha_try = 10.0**k\n",
        "  # declaramos el objeto del modelo\n",
        "  model = Ridge(alpha=current_alpha_try, fit_intercept=True)\n",
        "  # entrenamos el modelo con los datos de entrenamiento\n",
        "  model.fit(dataset['X_train'], dataset['y_train'])\n",
        "  models.append(model)\n",
        "  # predecimos con los datos de validación\n",
        "  y_hat_val = model.predict(dataset['X_val'])\n",
        "  # calculamos el MSE\n",
        "  mse_values[i] = mse(dataset['y_val'], y_hat_val)\n",
        "  # imprimimos por pantalla\n",
        "  print('alpha = {} - MSE = {}'.format(current_alpha_try, mse_values[i]))\n",
        "  i = i+1\n",
        "\n",
        "# recuperamos el mejor valor de alpha\n",
        "idx = np.argmin(mse_values)\n",
        "best_mse_on_validation = mse_values[idx]\n",
        "best_alpha = 10**alpha_values_exponents[idx]\n",
        "best_model = models[idx]\n",
        "print('=================')\n",
        "print('Best alpha value: {}'.format(best_alpha))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grid search\n",
            "=================\n",
            "alpha = 1e-05 - MSE = 39.43839588902205\n",
            "alpha = 0.0001 - MSE = 39.438393850006385\n",
            "alpha = 0.001 - MSE = 39.43837346304556\n",
            "alpha = 0.01 - MSE = 39.43816991279172\n",
            "alpha = 0.1 - MSE = 39.436166114622296\n",
            "alpha = 1.0 - MSE = 39.41908173158365\n",
            "alpha = 10.0 - MSE = 39.413609482747184\n",
            "alpha = 100.0 - MSE = 40.42953903824175\n",
            "alpha = 1000.0 - MSE = 45.04506942899651\n",
            "alpha = 10000.0 - MSE = 55.60639832993125\n",
            "=================\n",
            "Best alpha value: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdstwIta5zj_"
      },
      "source": [
        "Gráficamente veremos mejor lo que está pasando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3VBtg5hvZ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "3c7c4c3f-4603-4457-e35f-a8a5514ce105"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# mostramos gráficamente los resultados\n",
        "alpha_values_exponents = np.asarray(alpha_values_exponents)\n",
        "plt.semilogx(np.power(np.ones(alpha_values_exponents.shape)*10, alpha_values_exponents), mse_values)\n",
        "plt.title('Grid search for alpha parameter')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('MSE')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwcgjADJ57XU"
      },
      "source": [
        "Observando esta gráfica, podemos hacernos algunos planteos extra: ¿necesitamos ajustar un poco más el parámetro? ¿en qué rangos se mueven los mejores valores? ¿cuál es el modelo que mejor ajusta los datos, según los de validación? ¿necesitamos hacer random search? ¿cómo interpretamos el valor óptimo del parámetro?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn1Goc-qpFvS"
      },
      "source": [
        "### 6. Test\n",
        "\n",
        "Ahora que escogimos el mejor modelo, lo que sigue es evaluarlo sobre los datos de test. Para ello, vamos a simplemente predecir los resultados a partir de las features de test, y comparar las predicciones obtenidas con los valores reales de variables que tenemos. La evaluación la realizaremos con MSE, que es la métrica que escogimos para trabajar. Incluiremos también los valores de MSE en los datos de validación para comparar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXjQaQ_hpkcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53142350-1962-4105-b107-e08774d6d5ee"
      },
      "source": [
        "# generamos las predicciones sobre los datos de test\n",
        "y_hat_test = best_model.predict(dataset['X_test'])\n",
        "\n",
        "# comparamos las predicciones con los valores esperados usando MSE\n",
        "mse_test = mse(dataset['y_test'], y_hat_test)\n",
        "\n",
        "print('MSE on the validation set: {}'.format(best_mse_on_validation))\n",
        "print('MSE on the test set: {}'.format(mse_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE on the validation set: 39.413609482747184\n",
            "MSE on the test set: 24.26299531766248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e1GpipZ4sQi"
      },
      "source": [
        "En general esperamos que el error en los datos de validación sea menor al de los datos de test. ¿Por qué? Porque a los datos de validación los usamos para diseñar el modelo: escogimos el mejor valor de $\\alpha$ basándonos en la performance sobre esos datos, con lo cual tenemos ya un sesgo hacia sobreestimar la eficacia real del modelo. Los datos de test, por el contrario, operan como un conjunto totalmente, un conjunto de muestras que podríamos encontrarnos en la vida real, con nuestra aplicación deployada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67eOyQe44PvF"
      },
      "source": [
        "### 7. Control de overfitting/underfitting\n",
        "\n",
        "Algo que siempre debemos hacer cuando trabajamos en machine learning es analizar si nuestros datos tienen o no overfitting/underfitting.\n",
        "\n",
        "Un modelo con overfitting logró \"memorizar\" los datos de entrenamiento (ajustar sus parámetros hasta lograr un error muy bajo), a tal punto que cuando se aplica sobre datos nuevos diferentes a los de entrenamiento falla horriblemente.\n",
        "\n",
        "Un modelo con underfitting es su contraparte: es un modelo con poca capacidad, que no puede aprender nada de los datos de entrenamiento.\n",
        "\n",
        "Para evaluar underfitting/overfitting necesitamos entrenar el modelo y evaluarlo sobre los datos de entrenamiento y de validación. Si el modelo anda demasiado bien sobre los datos de entrenamiento pero falla horriblemente en los de validación, hay overfitting. Si el modelo anda horriblemente en los datos de entrenamiento, hay underfitting.\n",
        "\n",
        "El código a continuación evalúa los múltiples modelos posibles de Ridge Regression que podemos obtener para diferentes valores de $\\alpha$, evaluándolos tanto sobre los datos de entrenamiento como los de validación. Un buen ejercicio es reconocer cuáles tienen overfitting/underfitting y cuáles no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkd9vLAx-ZfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2915f2f9-ba47-4a92-bcf8-4be94956e06b"
      },
      "source": [
        "# probamos cada configuración\n",
        "print('Evaluating overfitting/underfitting')\n",
        "print('=================')\n",
        "for k in alpha_values_exponents:\n",
        "  # calculamos alpha\n",
        "  current_alpha_try = 10.0**k\n",
        "  # declaramos el objeto del modelo\n",
        "  model = Ridge(alpha=current_alpha_try, fit_intercept=True)\n",
        "  # entrenamos el modelo con los datos de entrenamiento\n",
        "  model.fit(dataset['X_train'], dataset['y_train'])\n",
        "  # predecimos con los datos de entrenamiento\n",
        "  y_hat_train = model.predict(dataset['X_train'])\n",
        "  # predecimos con los datos de validación\n",
        "  y_hat_val = model.predict(dataset['X_val'])\n",
        "  # calculamos el MSE en ambos casos\n",
        "  mse_train = mse(dataset['y_train'], y_hat_train)\n",
        "  mse_val = mse(dataset['y_val'], y_hat_val)\n",
        "  # imprimimos por pantalla\n",
        "  print('alpha = {}'.format(current_alpha_try, ))\n",
        "  print('- MSE training = {}'.format(mse_train))\n",
        "  print('- MSE validation = {}'.format(mse_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating overfitting/underfitting\n",
            "=================\n",
            "alpha = 1e-05\n",
            "- MSE training = 29.185323102288663\n",
            "- MSE validation = 39.43839588902205\n",
            "alpha = 0.0001\n",
            "- MSE training = 29.185323102320172\n",
            "- MSE validation = 39.438393850006385\n",
            "alpha = 0.001\n",
            "- MSE training = 29.18532310547061\n",
            "- MSE validation = 39.43837346304556\n",
            "alpha = 0.01\n",
            "- MSE training = 29.185323420297415\n",
            "- MSE validation = 39.43816991279172\n",
            "alpha = 0.1\n",
            "- MSE training = 29.18535468780395\n",
            "- MSE validation = 39.436166114622296\n",
            "alpha = 1.0\n",
            "- MSE training = 29.188280601069046\n",
            "- MSE validation = 39.41908173158365\n",
            "alpha = 10.0\n",
            "- MSE training = 29.364248888397697\n",
            "- MSE validation = 39.413609482747184\n",
            "alpha = 100.0\n",
            "- MSE training = 32.4340227860132\n",
            "- MSE validation = 40.42953903824175\n",
            "alpha = 1000.0\n",
            "- MSE training = 48.966691559711705\n",
            "- MSE validation = 45.04506942899651\n",
            "alpha = 10000.0\n",
            "- MSE training = 74.22427864567969\n",
            "- MSE validation = 55.60639832993125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H15trppzBZUu"
      },
      "source": [
        "### 8. Feature selection\n",
        "\n",
        "A menudo la etapa de model selection involucra, además, elegir el conjunto óptimo de features que nos asegura no estar empleando features irrelevantes.\n",
        "\n",
        "Existen numerosas formas de hacerlo. Las más usadas son aquellas que explotan [el uso de algún tipo de regularizador que permite descartar automáticamente las más inútiles](https://en.wikipedia.org/wiki/Lasso_(statistics)). Vamos a ver un ejemplo de este tipo de regularizadores más adelante en esta unidad, y en las clases que siguen.\n",
        "\n",
        "Otra alternativa más sencilla es, nuevamente, seguir un enfoque greedy. El más utilizado es uno conocido como [forward selection](https://towardsdatascience.com/feature-importance-and-forward-feature-selection-752638849962). Podemos entrenar $d$ modelos de una sola de las $d$ features que tenemos disponibles, y evaluar cada uno de ellos en los datos de validación. A partir de su performance en este conjunto, elegimos aquella que mejor anduvo. A continuación, probamos entrenar otros $p-1$ modelos con dos features esta vez, la que ya elegimos como la mejor y otra que utilizaremos de prueba. Nuevamente, evaluamos cada combinación sobre los datos de validación y elegimos el par que mejor funciona. Así, repetimos esta búsqueda hasta tanto agregar nuevas features no mejora la performance. Como resultado, obtendremos un conjunto de menos features en el que a priori descartamos algunas combinaciones que no nos sirven.\n",
        "\n",
        "¿Es óptimo? No. El óptimo es usar backtracking y explorar todas las posibles combinaciones. ¿Podemos hacerlo? Sí, si tenés tiempo y ganas. En la vida real, con un enfoque greedy estamos bien.\n",
        "\n",
        "El siguiente código hace feature selection de nuestro modelo utilizando este enfoque. Por simplicidad, fíjense que usamos un valor fijo de $\\alpha$. Sin embargo, lo ideal sería que para cada combinación de features probemos todos los valores de $\\alpha$, para quedarnos con la combinación más conveniente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9SvEUidDhBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cac976b-d4f9-4a11-a058-07d65bd7076a"
      },
      "source": [
        "import sys\n",
        "\n",
        "model = Ridge(alpha=10, fit_intercept=True)\n",
        "\n",
        "# inicializamos un arreglo vacío de features seleccionadas\n",
        "selected_features = np.zeros(dataset['X_train'].shape[1], dtype=np.bool)\n",
        "# inicializamos dos variables para llevar los MSE\n",
        "previous_best_mse = sys.maxsize\n",
        "current_best_mse = sys.maxsize - 1\n",
        "# y una variable que indique la nueva feature que se va a incorporar\n",
        "new_feature = None\n",
        "# recuperamos los nombres de las features\n",
        "feature_names = np.asarray(list(dataset['feature_labels'].keys()))\n",
        "\n",
        "# si el error en la iteración anterior fue mayor al nuevo error\n",
        "while (previous_best_mse > current_best_mse):\n",
        "\n",
        "  # agregamos la nueva feature al conjunto\n",
        "  if new_feature:\n",
        "    selected_features[new_feature] = True\n",
        "    print('New feature added: {}'.format(feature_names[new_feature]))\n",
        "    print('New set of features: {}'.format(feature_names[selected_features]))\n",
        "    print('MSE: {}'.format(current_best_mse))\n",
        "    print('============================')\n",
        "\n",
        "  # actualizamos los valores de mejor mse\n",
        "  previous_best_mse = current_best_mse\n",
        "\n",
        "  # inicializamos un arreglo para guardar el mse obtenido al probar cada feature\n",
        "  per_feature_mse = np.ones(selected_features.shape) * sys.maxsize\n",
        "\n",
        "  # iteramos por cada feature\n",
        "  for i in range(selected_features.size):\n",
        "\n",
        "    # si la feature no está seleccionada (no nos interesa volver a probar\n",
        "    # features de gusto)\n",
        "    if not (selected_features[i]):\n",
        "\n",
        "      # seleccionamos la feature a probar\n",
        "      features_to_try = selected_features.copy()\n",
        "      features_to_try[i] = True\n",
        "      # entrenamos el modelo\n",
        "      model.fit(dataset['X_train'][:,features_to_try], dataset['y_train'])\n",
        "      # lo evaluamos sobre los datos de validación\n",
        "      y_hat_val = model.predict(dataset['X_val'][:,features_to_try])\n",
        "      # registramos su performance\n",
        "      per_feature_mse[i] = mse(dataset['y_val'], y_hat_val) \n",
        "\n",
        "  # recuperamos el valor más bajo de MSE\n",
        "  new_feature = np.argmin(per_feature_mse)\n",
        "  current_best_mse = per_feature_mse[new_feature]\n",
        "\n",
        "# imprimimos el arreglo de mejores features\n",
        "print('FINAL SET OF FEATURES: {}'.format(feature_names[selected_features]))\n",
        "print('IGNORED FEATURES: {}'.format(feature_names[np.logical_not(selected_features)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New feature added: RM\n",
            "New set of features: ['RM']\n",
            "MSE: 51.23110384260224\n",
            "============================\n",
            "New feature added: CHAS\n",
            "New set of features: ['CHAS' 'RM']\n",
            "MSE: 46.75148230543749\n",
            "============================\n",
            "New feature added: AGE\n",
            "New set of features: ['CHAS' 'RM' 'AGE']\n",
            "MSE: 41.32904829035105\n",
            "============================\n",
            "FINAL SET OF FEATURES: ['CHAS' 'RM' 'AGE']\n",
            "IGNORED FEATURES: ['CRIM' 'ZN' 'INDUS' 'NOX' 'DIS' 'RAD' 'TAX' 'PTRATIO']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_F1bAh7sK1u"
      },
      "source": [
        "### 9. Cross-validation\n",
        "\n",
        "Cuando la cantidad de datos es poca o simplemente cuando queremos tener un estimador más robusto de la performance de nuestro método, se recomienda evitar las particiones fijas en training, validation y test y recurrir a una estrategia diferente conocida como validación cruzada o [cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).\n",
        "\n",
        "Para ilustrar esta estrategia, lo primero que haremos es descargar un nuevo data set, el [Pima Indians Diabetes Dataset](https://github.com/ignaciorlando/duia-ml-datasets/tree/master/PIMADataset). El mismo cuenta con datos y medidas clínicas de distintos pacientes, y una variable objetivo que indica a quiénes se les manifestará diabetes en 5 años. Esta variable toma dos valores: 0 (no se manifestará diabetes) y 1 (se manifestará). Se trata entonces de un problema de clasificación binaria en el que buscamos determinar la clase de un paciente dados sus datos y medidas clínicas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQY0z9KVtmfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dc0b65-019b-4216-ed74-281b480e66fa"
      },
      "source": [
        "# importamos el paquete para descargar archivos\n",
        "import wget\n",
        "from os import path\n",
        "\n",
        "# establecemos las características del data set\n",
        "pima_diabetes_dataset = dict()\n",
        "pima_diabetes_dataset['url'] = 'https://raw.githubusercontent.com/ignaciorlando/duia-ml-datasets/master/PIMADataset/pima-indians-diabetes.csv'\n",
        "pima_diabetes_dataset['extension'] = '.csv'\n",
        "pima_diabetes_dataset['filename'] = path.join(datasets_folder, 'pima_diabetes_dataset' + pima_diabetes_dataset['extension']) \n",
        "if not path.exists(pima_diabetes_dataset['filename']):  # descargar solamente si no existe\n",
        "  wget.download(pima_diabetes_dataset['url'], pima_diabetes_dataset['filename'])\n",
        "  print('Archivo descargado con éxito')\n",
        "else:\n",
        "  print('El archivo {} ya existe.'.format(pima_diabetes_dataset['filename']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El archivo /content/gdrive/My Drive/Colab Notebooks/DUIA/2021/Machine Learning/pima_diabetes_dataset.csv ya existe.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j03jwmmvLFQ"
      },
      "source": [
        "Abriremos el archivo como hicimos la clase pasada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U6Tq-VjvSeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee4ae22-7179-440f-ce09-f2193d878ba3"
      },
      "source": [
        "# abrimos el archivo de igual forma que antes, solo que indicando que el\n",
        "# delimitador de columnas es la coma\n",
        "raw_dataset = np.genfromtxt(pima_diabetes_dataset['filename'], delimiter=',')\n",
        "# verificamos el tamaño de la matriz que abrimos (filas x columnas)\n",
        "print('Dataset size: {}'.format(raw_dataset.shape))\n",
        "# imprimimos las primeras 5 filas para ver qué tipo de datos tenemos\n",
        "print('First 5 rows:')\n",
        "print(raw_dataset[0:4,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size: (768, 9)\n",
            "First 5 rows:\n",
            "[[  6.    148.     72.     35.      0.     33.6     0.627  50.      1.   ]\n",
            " [  1.     85.     66.     29.      0.     26.6     0.351  31.      0.   ]\n",
            " [  8.    183.     64.      0.      0.     23.3     0.672  32.      1.   ]\n",
            " [  1.     89.     66.     23.     94.     28.1     0.167  21.      0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12d15g_MvJBj"
      },
      "source": [
        "Las diferentes features involucradas son:\n",
        "\n",
        "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
        "- Diastolic blood pressure (mm Hg).\n",
        "- Triceps skinfold thickness (mm).\n",
        "- 2-Hour serum insulin (mu U/ml).\n",
        "- Body mass index (weight in kg/(height in m)^2).\n",
        "- Diabetes pedigree function.\n",
        "- Age (years).\n",
        "- Class variable (0 or 1).\n",
        "\n",
        "En principio no observamos ninguna feature que parezca indicar algún tipo de bias. Por ende, lo siguiente que tenemos que hacer es separar  la clase (variable objetivo) de las demás columnas (las features). Podemos hacer esto como la clase anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGjgvfkavyK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a37e285-d2a3-4ec8-e147-bee78b6fac29"
      },
      "source": [
        "# recuperamos únicamente las columnas que nos interesa mantener como features\n",
        "X = raw_dataset[:,0:8]\n",
        "# y armamos el arreglo de etiquetas\n",
        "y = raw_dataset[:,8]\n",
        "\n",
        "# chequeamos los tamaños de nuestros nuevos conjuntos\n",
        "print('X size: {}'.format(X.shape))\n",
        "print('y size: {}'.format(y.shape))\n",
        "# imprimimos las primeras 5 filas\n",
        "print('First 4 rows from the design matrix:')\n",
        "print(X[0:4,:])\n",
        "print('First 4 labels from the labels array:')\n",
        "print(y[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X size: (768, 8)\n",
            "y size: (768,)\n",
            "First 4 rows from the design matrix:\n",
            "[[  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
            " [  1.     85.     66.     29.      0.     26.6     0.351  31.   ]\n",
            " [  8.    183.     64.      0.      0.     23.3     0.672  32.   ]\n",
            " [  1.     89.     66.     23.     94.     28.1     0.167  21.   ]]\n",
            "First 4 labels from the labels array:\n",
            "[1. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqbTy46RxGYl"
      },
      "source": [
        "Si utilizáramos particiones fijas, ahora es el momento de dividir los datos en training, validation y test, y luego estandarizarlos. Utilizando cross-validation, la cosa cambia un poco. Vamos a usar como ejemplo para la evaluación el método de $k$-fold cross-validation, con $k=12$. Este proceso consiste en extraer $k$ particiones disjuntas (o folds) de los datos con $N / k$ muestras cada uno, que utilizaremos como múltiples test sets, y los restantes $N - (N / k)$ datos de cada fold serán divididos en conjuntos de entrenamiento y validación, respectivamente, que utilizaremos para entrenar y ajustar $k$ modelos. En nuestro ejemplo, tendremos 12 folds de test de 64 muestras cada uno, y $768 - 64 = 704$ muestras que tendremos que dividir en training y validation para entrenar y calibrar los modelos que evaluaremos sobre cada fold.\n",
        "\n",
        "![Fuente: http://qingkaikong.blogspot.com/2017/02/machine-learning-9-more-on-artificial.html](https://raw.githubusercontent.com/qingkaikong/blog/master/2017_05_More_on_applying_ANN/figures/figure_1.jpg)\n",
        "\n",
        "Lo primero que haremos entonces será construir los folds. Es importante tener en cuenta que los datos no están estandarizados, y que por ende necesitamos hacerlo antes de entrenar cualquier modelo. Para ello hay que tener en cuenta que los estadísticos que vamos a usar (media y desvío) van a tener que estimarse sobre los training sets de cada fold, y no sobre el conjunto de datos global.\n",
        "\n",
        "El siguiente código ejemplifica la construcción de los folds y la estandarización de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAlWGWfoxBjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0627f3fe-9924-41cc-d96d-c72e06506059"
      },
      "source": [
        "# determinamos la cantidad de folds\n",
        "k = 12\n",
        "# calculamos el tamaño de cada fold\n",
        "fold_size = X.shape[0] // k\n",
        "# y el de los conjuntos de training y validation\n",
        "training_set_size = round((X.shape[0] - k) * 0.9)\n",
        "\n",
        "# generamos una lista con los índices y la aleatorizamos\n",
        "idx = list(range(0,X.shape[0]))\n",
        "random.shuffle(idx)\n",
        "\n",
        "# construimos los folds\n",
        "start = 0             # inicializamos un iterador que marca el comienzo de cada fold\n",
        "k_fold_structure = [] # inicializamos la estructura donde los iremos guardando \n",
        "                      #(una lista de dicts() con cada k-fold)\n",
        "for i in range(0, k):\n",
        "  # \n",
        "  print('Building fold {}/{}'.format(i+1,k))\n",
        "  # tomamos las fold_size muestras que irán para test\n",
        "  X_test = X[idx[start:start+fold_size],:]\n",
        "  y_test = y[idx[start:start+fold_size]]\n",
        "  # recuperamos los índices de todas las demás muestras\n",
        "  if start == 0:\n",
        "    train_val_idx = idx[start+fold_size:]\n",
        "  elif (start + fold_size)==X.shape[0]:\n",
        "    train_val_idx = idx[0:start]\n",
        "  else:\n",
        "    train_val_idx = idx[0:start] + idx[start+fold_size:]\n",
        "  # la permutamos\n",
        "  random.shuffle(train_val_idx)\n",
        "  # tomamos el 90% para training y el restante 10% para validation\n",
        "  X_train = X[train_val_idx[0:training_set_size],:]\n",
        "  y_train = y[train_val_idx[0:training_set_size]]\n",
        "  X_val = X[train_val_idx[training_set_size:],:]\n",
        "  y_val = y[train_val_idx[training_set_size:]]\n",
        "  # calculamos la media y el desvío de los datos de entrenamiento\n",
        "  mu = np.mean(X_train, axis=0)\n",
        "  sigma = np.std(X_train, axis=0)\n",
        "  # estandarizamos los datos de training, validation y test\n",
        "  X_train = (X_train - mu) / sigma\n",
        "  X_val = (X_val - mu) / sigma\n",
        "  X_test = (X_test - mu) / sigma\n",
        "  # creamos el fold\n",
        "  fold = dict()\n",
        "  fold['X_train'] = X_train\n",
        "  fold['y_train'] = y_train\n",
        "  fold['X_val'] = X_val\n",
        "  fold['y_val'] = y_val\n",
        "  fold['X_test'] = X_test\n",
        "  fold['y_test'] = y_test\n",
        "  k_fold_structure.append(fold)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building fold 1/12\n",
            "Building fold 2/12\n",
            "Building fold 3/12\n",
            "Building fold 4/12\n",
            "Building fold 5/12\n",
            "Building fold 6/12\n",
            "Building fold 7/12\n",
            "Building fold 8/12\n",
            "Building fold 9/12\n",
            "Building fold 10/12\n",
            "Building fold 11/12\n",
            "Building fold 12/12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtAv-c8YoaZD"
      },
      "source": [
        "Ahora que tenemos los folds construidos, podemos aplicar $k$-fold cross-validation. El proceso consiste en los siguientes pasos:\n",
        "\n",
        "* Por cada $k$ fold del dataset:\n",
        "1. Entrenar un modelo con una configuración determinada sobre los datos de entrenamiento del fold.\n",
        "2. Evaluar el modelo sobre los datos de validación del fold.\n",
        "3. Repetir (1) y (2) utilizando configuraciones alternativas.\n",
        "4. Seleccionar el modelo con la configuración que mejor haya performado sobre los datos de validación.\n",
        "5. Evaluar el modelo del punto (4) en el fold de test y registrar la performance.\n",
        "* Tras recorrer todos los folds, analizar estadísticamente los resultados obtenidos.\n",
        "\n",
        "Como en todo proceso de evaluación, es necesario contar con una métrica que nos permita chequear la performance del modelo. En este caso, dado que se trata de un problema de clasificación, podemos utilizar una métrica conocida como [Accuracy](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers), que se calcula como:\n",
        "\n",
        "${\\mathit  {ACC}}=({\\mathit  {TP}}+{\\mathit  {TN}})/(P+N)$\n",
        "\n",
        "donde $\\mathit  {TP}$ es el número de true positives (valores clasificados como parte de la clase 1 y cuyas etiquetas reales son 1), $\\mathit  {TN}$ es el número de true negatives (valores clasificados como parte de la clase 0 y cuyas etiquetas reales son 0), $\\mathit  {P}$ es la cantidad total de muestras con etiquetas reales 1 y $\\mathit  {N}$ la cantidad total de muestras con etiquetas reales 0. También podemos expresar la ecuación en términos de operaciones de conjuntos:\n",
        "\n",
        "${\\mathit  {ACC}} = |y \\cap \\hat{y}| / |y|$\n",
        "\n",
        "donde $\\cap$ indica la intersección entre los conjuntos $y$ (etiquetas esperadas) y $\\hat{y}$ (etiquetas predichas por el modelo), y $| · |$ denota la cardinalidad (cantidad de elementos) de un conjunto. Esta métrica toma valores entre 0 y 1, siendo 0 cuando la intersección es vacía (la predicción no coincide en absoluto con las etiquetas esperadas) y 1 cuando la intersección es igual a $y$ (el modelo predijo todas las muestras correctamente).\n",
        "\n",
        "Con el siguiente código creamos una función que evalúa accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvjMfkTY0F2v"
      },
      "source": [
        "def accuracy(y, y_hat):\n",
        "  '''\n",
        "  Implementación de la métrica de Accuracy\n",
        "  '''\n",
        "\n",
        "  # calculamos el número de coincidencias\n",
        "  intersection = np.count_nonzero(y_hat == y)\n",
        "\n",
        "  return intersection / y.size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sMcouoN0GOL"
      },
      "source": [
        "Lo siguiente que nos falta es determinar qué modelo queremos probar. En este ejemplo emplearemos un clasificador binario conocido como [regresión logística (o logistic regression)](https://en.wikipedia.org/wiki/Logistic_regression), que veremos más adelante en la unidad de clasificación. Por lo pronto, basta con pensarlo como una caja negra que, dada una muestra, determina la probabilidad de que la misma pertenezca a la clase 1. Al igual que el modelo de regresión lineal, incluye un hiperparámetro $C$ que determina la influencia del regularizador en la función objetivo del clasificador durante el entrenamiento. En este caso $C = 1/\\lambda$ (o $1/\\alpha$, si usamos la notación que empleamos anteriormente para regresión lineal), con lo cual podemos interpretarlo como el inverso de la fuerza del regularizador. Así, cuanto más grande más se ignorará el término de regularización y menos se ignorará la función de error del clasificador.\n",
        "\n",
        "El hiperparámetro $C$ requiere un ajuste. De nuevo, utilizaremos valores $10^i$, con $i \\in \\{-5, -4, ..., 0, ..., 4, 5 \\}$. Para obtener el mejor valor posible, lo que haremos será utilizar los datos de validación de cada fold para cuantificar la performance de cada configuración, y seguiremos un proceso de grid search como hicimos anteriormente. Tengamos en cuenta que este proceso se repetirá mientras recorramos cada fold, y no una única vez como al utilizar particiones fijas. Esto incrementará indefectiblemente el costo computacional del entrenamiento.\n",
        "\n",
        "Pasamos, entonces, a aplicar $k$-fold cross-validation sobre nuestros $k=12$ folds, utilizando un modelo de regresión logística y la métrica de evaluación Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWxi40QtoZ0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0644ddbe-2f2b-4e7b-ef58-2702ce7814d4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# inicializamos un arreglo de valores de accuracy\n",
        "per_fold_accuracy = np.zeros(len(k_fold_structure))\n",
        "\n",
        "# inicializamos un arreglo de valores del parámetro C\n",
        "c_values_exponents = np.arange(-5,5,1)\n",
        "c_values = np.power(np.ones(c_values_exponents.shape) * 10, c_values_exponents)\n",
        "c_values_voting = np.zeros(c_values.shape)\n",
        "\n",
        "# vamos a iterar por cada fold\n",
        "for k in range(0,len(k_fold_structure)):\n",
        "\n",
        "  print('====================')\n",
        "  print('Evaluating {}/{} fold'.format(k+1, len(k_fold_structure)))\n",
        "  print('====================')\n",
        "\n",
        "  # recuperamos el k-ésimo fold\n",
        "  fold = k_fold_structure[k]\n",
        "  # inicializamos un arreglo de performances de validación\n",
        "  validation_performance = np.zeros(c_values.shape)\n",
        "\n",
        "  # evaluamos las múltiples configuraciones\n",
        "  i = 0\n",
        "  # iteramos por cada valor de C que queremos probar\n",
        "  for c in c_values:\n",
        "    # inicializamos el modelo con esa configuración\n",
        "    model = LogisticRegression(penalty='l2', C=c, solver='liblinear', fit_intercept=True)\n",
        "    # entrenamos sobre los datos de entrenamiento de este fold\n",
        "    model.fit(fold['X_train'], fold['y_train'])\n",
        "    # clasificamos los datos de validación\n",
        "    y_val_hat = model.predict(fold['X_val'])\n",
        "    # calculamos el accuracy de estos resultados\n",
        "    acc = accuracy(fold['y_val'], y_val_hat)\n",
        "    print('C = {}  ///  Accuracy = {}'.format(c, acc))\n",
        "    # lo registramos en nuestro arreglo de performances de validation\n",
        "    validation_performance[i] = acc\n",
        "    i = i+1\n",
        "\n",
        "  # buscamos el valor más alto de performance de validación\n",
        "  idx = np.argmax(validation_performance)\n",
        "  max_performance = validation_performance[idx]\n",
        "  # y el valor de C asociado\n",
        "  best_c_value = c_values[idx]\n",
        "  # incrementamos el voting para ese valor\n",
        "  c_values_voting[idx]+=1\n",
        "  # lo reportamos por pantalla\n",
        "  print('Best C value: {} (Acc = {})'.format(best_c_value, max_performance))\n",
        "\n",
        "  # evaluamos el modelo óptimo sobre los datos de test\n",
        "  model = LogisticRegression(penalty='l2', C=best_c_value, solver='liblinear', fit_intercept=True)\n",
        "  model.fit(fold['X_train'], fold['y_train'])\n",
        "  y_test_hat = model.predict(fold['X_test'])\n",
        "  # calculamos el accuracy de estos resultados\n",
        "  acc = accuracy(fold['y_test'], y_test_hat)\n",
        "  # y lo registramos en el arreglo de performances\n",
        "  per_fold_accuracy[k] = acc\n",
        "  print('')\n",
        "  print('Acc on the test set = {}'.format(acc))\n",
        "  print('')\n",
        "\n",
        "print('********************************')\n",
        "print('k-fold cross validation finished!')\n",
        "print('********************************')\n",
        "print('C values = 10^k: {}'.format(c_values_exponents))\n",
        "print('Voting for C values: {}'.format(c_values_voting))\n",
        "print('Average performance: Acc = {}'.format(np.mean(per_fold_accuracy)))\n",
        "print('Stdev performance: Acc = {}'.format(np.std(per_fold_accuracy)))\n",
        "\n",
        "l2_model_performance = per_fold_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "Evaluating 1/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.6666666666666666\n",
            "C = 0.0001  ///  Accuracy = 0.6666666666666666\n",
            "C = 0.001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.01  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.1  ///  Accuracy = 0.75\n",
            "C = 1.0  ///  Accuracy = 0.75\n",
            "C = 10.0  ///  Accuracy = 0.75\n",
            "C = 100.0  ///  Accuracy = 0.75\n",
            "C = 1000.0  ///  Accuracy = 0.75\n",
            "C = 10000.0  ///  Accuracy = 0.75\n",
            "Best C value: 0.01 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.859375\n",
            "\n",
            "====================\n",
            "Evaluating 2/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.0001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.01  ///  Accuracy = 0.6666666666666666\n",
            "C = 0.1  ///  Accuracy = 0.6666666666666666\n",
            "C = 1.0  ///  Accuracy = 0.6666666666666666\n",
            "C = 10.0  ///  Accuracy = 0.6666666666666666\n",
            "C = 100.0  ///  Accuracy = 0.6666666666666666\n",
            "C = 1000.0  ///  Accuracy = 0.6666666666666666\n",
            "C = 10000.0  ///  Accuracy = 0.6666666666666666\n",
            "Best C value: 1e-05 (Acc = 0.7083333333333334)\n",
            "\n",
            "Acc on the test set = 0.8125\n",
            "\n",
            "====================\n",
            "Evaluating 3/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.5833333333333334\n",
            "C = 0.0001  ///  Accuracy = 0.5833333333333334\n",
            "C = 0.001  ///  Accuracy = 0.5833333333333334\n",
            "C = 0.01  ///  Accuracy = 0.5833333333333334\n",
            "C = 0.1  ///  Accuracy = 0.625\n",
            "C = 1.0  ///  Accuracy = 0.625\n",
            "C = 10.0  ///  Accuracy = 0.625\n",
            "C = 100.0  ///  Accuracy = 0.625\n",
            "C = 1000.0  ///  Accuracy = 0.625\n",
            "C = 10000.0  ///  Accuracy = 0.625\n",
            "Best C value: 0.1 (Acc = 0.625)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "====================\n",
            "Evaluating 4/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.625\n",
            "C = 0.0001  ///  Accuracy = 0.625\n",
            "C = 0.001  ///  Accuracy = 0.625\n",
            "C = 0.01  ///  Accuracy = 0.5833333333333334\n",
            "C = 0.1  ///  Accuracy = 0.625\n",
            "C = 1.0  ///  Accuracy = 0.625\n",
            "C = 10.0  ///  Accuracy = 0.625\n",
            "C = 100.0  ///  Accuracy = 0.625\n",
            "C = 1000.0  ///  Accuracy = 0.625\n",
            "C = 10000.0  ///  Accuracy = 0.625\n",
            "Best C value: 1e-05 (Acc = 0.625)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "====================\n",
            "Evaluating 5/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.0001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.01  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.1  ///  Accuracy = 0.8333333333333334\n",
            "C = 1.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 100.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 1000.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10000.0  ///  Accuracy = 0.8333333333333334\n",
            "Best C value: 0.1 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.84375\n",
            "\n",
            "====================\n",
            "Evaluating 6/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.0001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.001  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.01  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.1  ///  Accuracy = 0.7916666666666666\n",
            "C = 1.0  ///  Accuracy = 0.7916666666666666\n",
            "C = 10.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 100.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 1000.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10000.0  ///  Accuracy = 0.8333333333333334\n",
            "Best C value: 10.0 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "====================\n",
            "Evaluating 7/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.0001  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.001  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.01  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.1  ///  Accuracy = 0.8333333333333334\n",
            "C = 1.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 100.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 1000.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10000.0  ///  Accuracy = 0.8333333333333334\n",
            "Best C value: 1e-05 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.8125\n",
            "\n",
            "====================\n",
            "Evaluating 8/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.875\n",
            "C = 0.0001  ///  Accuracy = 0.8333333333333334\n",
            "C = 0.001  ///  Accuracy = 0.875\n",
            "C = 0.01  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.1  ///  Accuracy = 0.7916666666666666\n",
            "C = 1.0  ///  Accuracy = 0.75\n",
            "C = 10.0  ///  Accuracy = 0.75\n",
            "C = 100.0  ///  Accuracy = 0.75\n",
            "C = 1000.0  ///  Accuracy = 0.75\n",
            "C = 10000.0  ///  Accuracy = 0.75\n",
            "Best C value: 1e-05 (Acc = 0.875)\n",
            "\n",
            "Acc on the test set = 0.8125\n",
            "\n",
            "====================\n",
            "Evaluating 9/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.0001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.01  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.1  ///  Accuracy = 0.8333333333333334\n",
            "C = 1.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 100.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 1000.0  ///  Accuracy = 0.8333333333333334\n",
            "C = 10000.0  ///  Accuracy = 0.8333333333333334\n",
            "Best C value: 0.1 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.84375\n",
            "\n",
            "====================\n",
            "Evaluating 10/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.75\n",
            "C = 0.0001  ///  Accuracy = 0.75\n",
            "C = 0.001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.01  ///  Accuracy = 0.75\n",
            "C = 0.1  ///  Accuracy = 0.75\n",
            "C = 1.0  ///  Accuracy = 0.75\n",
            "C = 10.0  ///  Accuracy = 0.75\n",
            "C = 100.0  ///  Accuracy = 0.75\n",
            "C = 1000.0  ///  Accuracy = 0.75\n",
            "C = 10000.0  ///  Accuracy = 0.75\n",
            "Best C value: 0.001 (Acc = 0.7916666666666666)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "====================\n",
            "Evaluating 11/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.0001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.01  ///  Accuracy = 0.7083333333333334\n",
            "C = 0.1  ///  Accuracy = 0.7083333333333334\n",
            "C = 1.0  ///  Accuracy = 0.7083333333333334\n",
            "C = 10.0  ///  Accuracy = 0.7083333333333334\n",
            "C = 100.0  ///  Accuracy = 0.7083333333333334\n",
            "C = 1000.0  ///  Accuracy = 0.7083333333333334\n",
            "C = 10000.0  ///  Accuracy = 0.7083333333333334\n",
            "Best C value: 1e-05 (Acc = 0.7916666666666666)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "====================\n",
            "Evaluating 12/12 fold\n",
            "====================\n",
            "C = 1e-05  ///  Accuracy = 0.75\n",
            "C = 0.0001  ///  Accuracy = 0.75\n",
            "C = 0.001  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.01  ///  Accuracy = 0.7916666666666666\n",
            "C = 0.1  ///  Accuracy = 0.75\n",
            "C = 1.0  ///  Accuracy = 0.75\n",
            "C = 10.0  ///  Accuracy = 0.75\n",
            "C = 100.0  ///  Accuracy = 0.75\n",
            "C = 1000.0  ///  Accuracy = 0.75\n",
            "C = 10000.0  ///  Accuracy = 0.75\n",
            "Best C value: 0.001 (Acc = 0.7916666666666666)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "********************************\n",
            "k-fold cross validation finished!\n",
            "********************************\n",
            "C values = 10^k: [-5 -4 -3 -2 -1  0  1  2  3  4]\n",
            "Voting for C values: [5. 0. 2. 1. 3. 0. 1. 0. 0. 0.]\n",
            "Average performance: Acc = 0.8294270833333334\n",
            "Stdev performance: Acc = 0.013468854730193488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZms63H7zhwk"
      },
      "source": [
        "En este caso decidimos interpretar los datos en función de su media y desvío. La media nos dice en promedio qué performance tuvimos a lo largo de todos los folds. El desvío estándar, por otro lado, nos dice qué tan dispersos están esos valores de accuracy: si el desvío es alto, eso significa que para algunos folds la performance es alta y para otros es baja. Existen diversas causas para que ocurra eso: que los datos no sean representativos, que las clases estén desbalanceadas, que los hiperparámetros estudiados requieran mayor análisis o que el modelo no sea el apropiado. A medida que avancemos en las clases veremos cómo diganosticar estos problemas, y cómo resolverlos (o aliviarlos).\n",
        "\n",
        "Un último punto tiene que ver con cómo deployar un modelo entrenado y evaluado con cross-validation. ¿Qué modelo elegimos? ¿Entrenado en qué fold? ¿Con qué parámetros? En realidad, usualmente lo que se hace es reentrenar el modelo utilizando todo el conjunto de datos existente (no ya los folds, se considera a todo el dataset como una única partición de training). La configuración de hiperparámetros que se elige es la que que hayamos visto como más efectiva en la evaluación por folds, y lo obtenemos registrando el parámetro óptimo seleccionado en cada iteración (como hicimos en el arreglo ```c_values_voting``` en el código anterior) y quedándonos con el que haya sido seleccionado en la mayor cantidad de casos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE98x7WZAi0U"
      },
      "source": [
        "### 10. Comparación de modelos\n",
        "\n",
        "Supongamos ahora que queremos evaluar otro modelo alternativo, y estudiar cuál es los dos es mejor para una aplicación en concreto.\n",
        "El modelo que estudiaremos es el de regresión logística nuevamente, pero esta vez cambiaremos la estrategia de regularización: en lugar de usar L2 (que es la misma que se utiliza para ridge regression y que penaliza que los pesos se vayan muy altos), utilizaremos L1 (que tiene como efecto conocido intentar que la mayor cantidad posible de pesos sea igual a 0). Veremos más adelante el detalle de cada regularizador, pero ahora quedémonos con que el modelo entrenado con L1 es distinto al entrenado con L2, y queremos saber cuál es mejor.\n",
        "\n",
        "Para ello, podemos plantear el mismo proceso de k-fold cross-validation que usamos anteriormente. Registraremos la performance en un nuevo arreglo, que utilizaremos para comparar con el arreglo de performance del modelo con L2. El modelo tiene también a $C$ como único hiperparámetro, y su función es idéntica a la del regularizado con L2: determinar el trade-off entre regularización y error de entrenamiento.\n",
        "\n",
        "Ejecutemos esta secuencia para cuantificar la performance del modelo con L1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK4mki1WCcJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e6af5f-fcdf-40a6-8997-033d571d0b9c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# inicializamos un arreglo de valores de accuracy\n",
        "per_fold_accuracy = np.zeros(len(k_fold_structure))\n",
        "\n",
        "# inicializamos un arreglo de valores del parámetro C\n",
        "c_values_exponents = np.arange(-5,5,1)\n",
        "c_values = np.power(np.ones(c_values_exponents.shape) * 10, c_values_exponents)\n",
        "c_values_voting = np.zeros(c_values.shape)\n",
        "\n",
        "# vamos a iterar por cada fold\n",
        "for k in range(0,len(k_fold_structure)):\n",
        "\n",
        "  print('====================')\n",
        "  print('Evaluating {}/{} fold'.format(k+1, len(k_fold_structure)))\n",
        "  print('====================')\n",
        "\n",
        "  # recuperamos el k-ésimo fold\n",
        "  fold = k_fold_structure[k]\n",
        "  # inicializamos un arreglo de performances de validación\n",
        "  validation_performance = np.zeros(c_values.shape)\n",
        "\n",
        "  # evaluamos las múltiples configuraciones\n",
        "  i = 0\n",
        "  # iteramos por cada valor de C que queremos probar\n",
        "  for c in c_values:\n",
        "    # inicializamos el modelo con esa configuración\n",
        "    model = LogisticRegression(penalty='l1', C=c, solver='liblinear', fit_intercept=True)\n",
        "    # entrenamos sobre los datos de entrenamiento de este fold\n",
        "    model.fit(fold['X_train'], fold['y_train'])\n",
        "    # clasificamos los datos de validación\n",
        "    y_val_hat = model.predict(fold['X_val'])\n",
        "    # calculamos el accuracy de estos resultados\n",
        "    acc = accuracy(fold['y_val'], y_val_hat)\n",
        "    print(f'C = {c:2.2e}  ///  Accuracy = {acc:4.3}')\n",
        "    # lo registramos en nuestro arreglo de performances de validation\n",
        "    validation_performance[i] = acc\n",
        "    i = i+1\n",
        "\n",
        "  # buscamos el valor más alto de performance de validación\n",
        "  idx = np.argmax(validation_performance)\n",
        "  max_performance = validation_performance[idx]\n",
        "  # y el valor de C asociado\n",
        "  best_c_value = c_values[idx]\n",
        "  # incrementamos el voting para ese valor\n",
        "  c_values_voting[idx]+=1\n",
        "  # lo reportamos por pantalla\n",
        "  print('Best C value: {} (Acc = {})'.format(best_c_value, max_performance))\n",
        "\n",
        "  # evaluamos el modelo óptimo sobre los datos de test\n",
        "  model = LogisticRegression(penalty='l1', C=best_c_value, solver='liblinear', fit_intercept=True)\n",
        "  model.fit(fold['X_train'], fold['y_train'])\n",
        "  y_test_hat = model.predict(fold['X_test'])\n",
        "  # calculamos el accuracy de estos resultados\n",
        "  acc = accuracy(fold['y_test'], y_test_hat)\n",
        "  # y lo registramos en el arreglo de performances\n",
        "  per_fold_accuracy[k] = acc\n",
        "  print('')\n",
        "  print('Acc on the test set = {}'.format(acc))\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "print('********************************')\n",
        "print('k-fold cross validation finished!')\n",
        "print('********************************')\n",
        "print('Voting for C values: {}'.format(c_values_voting))\n",
        "print('Average performance: Acc = {}'.format(np.mean(per_fold_accuracy)))\n",
        "print('Stdev performance: Acc = {}'.format(np.std(per_fold_accuracy)))\n",
        "\n",
        "l1_model_performance = per_fold_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "Evaluating 1/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.542\n",
            "C = 1.00e-04  ///  Accuracy = 0.542\n",
            "C = 1.00e-03  ///  Accuracy = 0.542\n",
            "C = 1.00e-02  ///  Accuracy = 0.667\n",
            "C = 1.00e-01  ///  Accuracy = 0.708\n",
            "C = 1.00e+00  ///  Accuracy = 0.75\n",
            "C = 1.00e+01  ///  Accuracy = 0.75\n",
            "C = 1.00e+02  ///  Accuracy = 0.75\n",
            "C = 1.00e+03  ///  Accuracy = 0.75\n",
            "C = 1.00e+04  ///  Accuracy = 0.75\n",
            "Best C value: 1.0 (Acc = 0.75)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 2/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.583\n",
            "C = 1.00e-04  ///  Accuracy = 0.583\n",
            "C = 1.00e-03  ///  Accuracy = 0.583\n",
            "C = 1.00e-02  ///  Accuracy = 0.542\n",
            "C = 1.00e-01  ///  Accuracy = 0.667\n",
            "C = 1.00e+00  ///  Accuracy = 0.667\n",
            "C = 1.00e+01  ///  Accuracy = 0.667\n",
            "C = 1.00e+02  ///  Accuracy = 0.667\n",
            "C = 1.00e+03  ///  Accuracy = 0.667\n",
            "C = 1.00e+04  ///  Accuracy = 0.667\n",
            "Best C value: 0.1 (Acc = 0.6666666666666666)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 3/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.625\n",
            "C = 1.00e-04  ///  Accuracy = 0.625\n",
            "C = 1.00e-03  ///  Accuracy = 0.625\n",
            "C = 1.00e-02  ///  Accuracy = 0.583\n",
            "C = 1.00e-01  ///  Accuracy = 0.583\n",
            "C = 1.00e+00  ///  Accuracy = 0.625\n",
            "C = 1.00e+01  ///  Accuracy = 0.625\n",
            "C = 1.00e+02  ///  Accuracy = 0.625\n",
            "C = 1.00e+03  ///  Accuracy = 0.625\n",
            "C = 1.00e+04  ///  Accuracy = 0.625\n",
            "Best C value: 1e-05 (Acc = 0.625)\n",
            "\n",
            "Acc on the test set = 0.640625\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 4/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.542\n",
            "C = 1.00e-04  ///  Accuracy = 0.542\n",
            "C = 1.00e-03  ///  Accuracy = 0.542\n",
            "C = 1.00e-02  ///  Accuracy = 0.625\n",
            "C = 1.00e-01  ///  Accuracy = 0.583\n",
            "C = 1.00e+00  ///  Accuracy = 0.625\n",
            "C = 1.00e+01  ///  Accuracy = 0.625\n",
            "C = 1.00e+02  ///  Accuracy = 0.625\n",
            "C = 1.00e+03  ///  Accuracy = 0.625\n",
            "C = 1.00e+04  ///  Accuracy = 0.625\n",
            "Best C value: 0.01 (Acc = 0.625)\n",
            "\n",
            "Acc on the test set = 0.796875\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 5/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.708\n",
            "C = 1.00e-04  ///  Accuracy = 0.708\n",
            "C = 1.00e-03  ///  Accuracy = 0.708\n",
            "C = 1.00e-02  ///  Accuracy = 0.625\n",
            "C = 1.00e-01  ///  Accuracy = 0.792\n",
            "C = 1.00e+00  ///  Accuracy = 0.833\n",
            "C = 1.00e+01  ///  Accuracy = 0.833\n",
            "C = 1.00e+02  ///  Accuracy = 0.833\n",
            "C = 1.00e+03  ///  Accuracy = 0.833\n",
            "C = 1.00e+04  ///  Accuracy = 0.833\n",
            "Best C value: 1.0 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.84375\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 6/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.667\n",
            "C = 1.00e-04  ///  Accuracy = 0.667\n",
            "C = 1.00e-03  ///  Accuracy = 0.667\n",
            "C = 1.00e-02  ///  Accuracy = 0.792\n",
            "C = 1.00e-01  ///  Accuracy = 0.792\n",
            "C = 1.00e+00  ///  Accuracy = 0.792\n",
            "C = 1.00e+01  ///  Accuracy = 0.833\n",
            "C = 1.00e+02  ///  Accuracy = 0.833\n",
            "C = 1.00e+03  ///  Accuracy = 0.833\n",
            "C = 1.00e+04  ///  Accuracy = 0.833\n",
            "Best C value: 10.0 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 7/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.708\n",
            "C = 1.00e-04  ///  Accuracy = 0.708\n",
            "C = 1.00e-03  ///  Accuracy = 0.708\n",
            "C = 1.00e-02  ///  Accuracy = 0.708\n",
            "C = 1.00e-01  ///  Accuracy = 0.833\n",
            "C = 1.00e+00  ///  Accuracy = 0.833\n",
            "C = 1.00e+01  ///  Accuracy = 0.833\n",
            "C = 1.00e+02  ///  Accuracy = 0.833\n",
            "C = 1.00e+03  ///  Accuracy = 0.833\n",
            "C = 1.00e+04  ///  Accuracy = 0.833\n",
            "Best C value: 0.1 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 8/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.625\n",
            "C = 1.00e-04  ///  Accuracy = 0.625\n",
            "C = 1.00e-03  ///  Accuracy = 0.625\n",
            "C = 1.00e-02  ///  Accuracy = 0.833\n",
            "C = 1.00e-01  ///  Accuracy = 0.833\n",
            "C = 1.00e+00  ///  Accuracy = 0.792\n",
            "C = 1.00e+01  ///  Accuracy = 0.75\n",
            "C = 1.00e+02  ///  Accuracy = 0.75\n",
            "C = 1.00e+03  ///  Accuracy = 0.75\n",
            "C = 1.00e+04  ///  Accuracy = 0.75\n",
            "Best C value: 0.01 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.796875\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 9/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.583\n",
            "C = 1.00e-04  ///  Accuracy = 0.583\n",
            "C = 1.00e-03  ///  Accuracy = 0.583\n",
            "C = 1.00e-02  ///  Accuracy = 0.792\n",
            "C = 1.00e-01  ///  Accuracy = 0.792\n",
            "C = 1.00e+00  ///  Accuracy = 0.833\n",
            "C = 1.00e+01  ///  Accuracy = 0.833\n",
            "C = 1.00e+02  ///  Accuracy = 0.833\n",
            "C = 1.00e+03  ///  Accuracy = 0.833\n",
            "C = 1.00e+04  ///  Accuracy = 0.833\n",
            "Best C value: 1.0 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.84375\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 10/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.667\n",
            "C = 1.00e-04  ///  Accuracy = 0.667\n",
            "C = 1.00e-03  ///  Accuracy = 0.667\n",
            "C = 1.00e-02  ///  Accuracy = 0.708\n",
            "C = 1.00e-01  ///  Accuracy = 0.792\n",
            "C = 1.00e+00  ///  Accuracy = 0.75\n",
            "C = 1.00e+01  ///  Accuracy = 0.75\n",
            "C = 1.00e+02  ///  Accuracy = 0.75\n",
            "C = 1.00e+03  ///  Accuracy = 0.75\n",
            "C = 1.00e+04  ///  Accuracy = 0.75\n",
            "Best C value: 0.1 (Acc = 0.7916666666666666)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 11/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.542\n",
            "C = 1.00e-04  ///  Accuracy = 0.542\n",
            "C = 1.00e-03  ///  Accuracy = 0.542\n",
            "C = 1.00e-02  ///  Accuracy = 0.708\n",
            "C = 1.00e-01  ///  Accuracy = 0.708\n",
            "C = 1.00e+00  ///  Accuracy = 0.708\n",
            "C = 1.00e+01  ///  Accuracy = 0.708\n",
            "C = 1.00e+02  ///  Accuracy = 0.708\n",
            "C = 1.00e+03  ///  Accuracy = 0.708\n",
            "C = 1.00e+04  ///  Accuracy = 0.708\n",
            "Best C value: 0.01 (Acc = 0.7083333333333334)\n",
            "\n",
            "Acc on the test set = 0.796875\n",
            "\n",
            "\n",
            "====================\n",
            "Evaluating 12/12 fold\n",
            "====================\n",
            "C = 1.00e-05  ///  Accuracy = 0.667\n",
            "C = 1.00e-04  ///  Accuracy = 0.667\n",
            "C = 1.00e-03  ///  Accuracy = 0.667\n",
            "C = 1.00e-02  ///  Accuracy = 0.792\n",
            "C = 1.00e-01  ///  Accuracy = 0.833\n",
            "C = 1.00e+00  ///  Accuracy = 0.75\n",
            "C = 1.00e+01  ///  Accuracy = 0.75\n",
            "C = 1.00e+02  ///  Accuracy = 0.75\n",
            "C = 1.00e+03  ///  Accuracy = 0.75\n",
            "C = 1.00e+04  ///  Accuracy = 0.75\n",
            "Best C value: 0.1 (Acc = 0.8333333333333334)\n",
            "\n",
            "Acc on the test set = 0.828125\n",
            "\n",
            "\n",
            "********************************\n",
            "k-fold cross validation finished!\n",
            "********************************\n",
            "Voting for C values: [1. 0. 0. 3. 4. 3. 1. 0. 0. 0.]\n",
            "Average performance: Acc = 0.8072916666666666\n",
            "Stdev performance: Acc = 0.052730356071136936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCCdMTH1pVTo"
      },
      "source": [
        "Podemos comparar las medias y desvíos de cada modelo para decidir cuál es el mejor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBAFptvpgFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd04e63c-f34b-44fc-d727-a34d56f5f78b"
      },
      "source": [
        "print('Mean +- standard deviation performance of logistic regression classifiers:')\n",
        "print('with L2 regularization: {:05.4f} +- {:05.4f}'.format(np.mean(l2_model_performance),\n",
        "                                                            np.std(l2_model_performance)))\n",
        "print('with L1 regularization: {:05.4f} +- {:05.4f}'.format(np.mean(l1_model_performance),\n",
        "                                                            np.std(l1_model_performance)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean +- standard deviation performance of logistic regression classifiers:\n",
            "with L2 regularization: 0.8294 +- 0.0135\n",
            "with L1 regularization: 0.8073 +- 0.0527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WKiZqJ8pa2L"
      },
      "source": [
        "El accuracy es mejor cuanto más cercano a 1 es, con lo cual podemos decidir qué modelo es el mejor comparando las medias y quedarnos con el que mayor valor tenga. \n",
        "\n",
        "El desvío estándar nos permite validar cuál de los modelos tiene resultados más variables entre folds. Al momento de elegir el mejor entre dos modelos con idéntica media, solemos escoger aquel que menos variabilidad entre folds tuvo.\n",
        "\n",
        "Para terminar, otra forma de comparar modelos es utilizando [boxplots](https://en.wikipedia.org/wiki/Box_plot). En estos gráficos utilizamos una caja por modelo. Cada caja representar la distribución de valores de performance del algoritmo, de forma tal que el borde inferior de la caja representa el cuartil 1, la línea central (naranja) la mediana o cuartil 2 y la línea superior el cuartil 3. Además, se incorporan \"bigotes\" (whiskers) cuyos bordes inferiores / superiores representan el mínimo y máximo valor del conjunto (cuartil 0 y cuartil 4). Finalmente, algunas librerías agregan círculos para representar outliers (valores extremadamente altos o bajos que no se condicen con la distribución general de los datos). El mejor modelo según un boxplot es aquel cuya caja está más arriba (si la métrica de performance es mejor cuando es alta, como en este caso) y con los bigotes y las cajas lo más pequeñas posibles (menos variabilidad en los datos). \n",
        "\n",
        "El siguiente código grafica la performance de cada modelo utilizando boxplots: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Dna3MVrQ5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100890c1-d958-42bc-b09d-c39e0ec6f689"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.boxplot(np.stack((l2_model_performance, l1_model_performance),axis=1),\n",
        "            labels=('L2', 'L1'))\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIjUXEouXVU"
      },
      "source": [
        "Con esto ya tenemos todas las herramientas para, dado un conjunto de datos, poder decidir qué catálogo de soluciones aplicar, cómo entrenar las soluciones usando particiones fijas o cross-validation, cómo ajustar los modelos a partir de datos de validación y cómo determinar cuál es el mejor modelo.\n",
        "\n",
        "Lo que sigue es empezar a ver uno por uno los modelos de machine learning para cada tipo de problema, y sus ventajas y desventajas. Pero eso toca en la próxima clase :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCap945CoVye"
      },
      "source": [
        "### Bonus Track: Algunas instrucciones Python para ser más eficientes\n",
        "\n",
        "Hasta aquí hemos implementado todos los algoritmos manualmente, para poder entender cómo es que funcionan. La buena noticia es que no vamos a necesitar hacer eso permanentemente. Por suerte, Python nos ofrece varias librerías que nos permiten resolver estas mismas cosas más eficientemente.\n",
        "\n",
        "El paquete [model_selection de sklearn](https://scikit-learn.org/stable/model_selection.html) ofrece rutinas para hacer cross-validation, calibrar hiperparámetros, métricas para distintos tipos de problemas y para hacer representaciones visuales. Si tienen un rato, chequeen cómo funcionan!"
      ]
    }
  ]
}